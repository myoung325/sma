/* -*- mode: javascript; js-indent-level: 2 -*- */

// Copyright 2022 Stefan Zager <szager@gmail.com>
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

/*
Stop Motion Animator
On GitHub: https://github.com/myoung325/sma
This is a fork of: https://github.com/szager/stop-motion
This fork was made almost entirely using genAI, namely ChatGPT, with prompting and code insertion by Mike Young, to re-tool the original project for the following:
 * Added PWA support.
 * Tweaked the GUI and making it scale with respect to window size.
 * Replaced button graphics, generated by Gemini.
 * Added support for higher resolution cameras.  The app will select the highest supported resolution from a preset list and display the selected resolution at the top-right.
 * Increased output video quality by specifying "0.99999" in "imageCanvas.toBlob(blob => { resolve(blob) }, 'image/webp', 0.99999);" in animator.js
 * Changed selectable FPS range from 5fps to 30fps, in single frame increments.
 * Made the On/Off button control enabling/disabling onion skinning.
 * Disabled/hid the clock feature.
 * Disabled the red progress line/dot when playing footage.
 * Changed audio recording buttons from SVGs to PNGs.
 * Made audio recording countdown appear over the video preview.
*/

'use strict';

var animator = animator || {};

(() => {
  // Animator states (for possible extension/use elsewhere)
  const STATE_IDLE   = 0;
  const STATE_PLAY   = 1;
  const STATE_RECORD = 2;

  /**
   * Animator class for stop-motion animation.
   * Handles video stream input, frame capture, onion skinning,
   * playback, saving, and audio recording.
   */
  class Animator {
    /**
     * @param {HTMLVideoElement} video - Video element for live camera feed.
     * @param {HTMLCanvasElement} snapshotCanvas - Canvas used for onion skin preview.
     * @param {HTMLCanvasElement} playCanvas - Canvas used for playback.
     * @param {HTMLElement} messageDiv - Element for displaying messages to the user.
     */
    constructor(video, snapshotCanvas, playCanvas, messageDiv) {
      // Video stream and playback components
      this.video = video;
      this.videoStream = null;
      this.snapshotCanvas = snapshotCanvas;
      this.snapshotContext = snapshotCanvas.getContext('2d');
      this.playCanvas = playCanvas;
      this.playContext = playCanvas.getContext('2d');
      this.playTimer = null;

      // Control flags
      this._flip = false;             // Whether video capture is flipped
      this.streamOn = true;           // Camera stream active flag
      this.onionSkinEnabled = true;   // Onion skin overlay enabled

      // UI and metadata
      this.messageDiv = messageDiv;
      this.playbackSpeed = 24.0;      // Frames per second
      this.name = null;

      // Frame storage
      this.frames = [];       // Array of captured frame canvases
      this.frameWebps = [];   // Array of promises for compressed frame blobs

      // Dimensions (set later when video metadata is available)
      this.w = 0;
      this.h = 0;

      // Frame loading management
      this.framesInFlight = 0;
      this.loadFinishPending = false;

      // Audio handling
      this.audio = null;
      this.audioRecorder = null;
      this.audioChunks = [];
      this.audioBlob = null;

      // Playback synchronization
      this.zeroPlayTime = 0;

      // audio handling (shutter): preload short shutter sound for low latency
      this.shutterUrl = 'sounds/shutter.ogg';
      this.shutterAudio = null;
      this._preloadShutter();
    }

    /**
     * Preload shutter sound into an Audio object and also warm a small fetch
     * so Service Worker cache gets used (if installed).
     */
    _preloadShutter() {
      try {
        // Create one Audio object and keep it for quick reuse
        this.shutterAudio = new Audio(this.shutterUrl);

        // Set low-latency hints where supported
        this.shutterAudio.preload = 'auto';
        // Optional: set small volume
        // this.shutterAudio.volume = 0.9;

        // Warm the resource via fetch so SW cache is used (no-op if offline cached)
        fetch(this.shutterUrl, { cache: 'force-cache' }).catch(() => {
          // ignore fetch errors (offline or not cached yet)
        });
      } catch (err) {
        console.warn('Shutter preload failed:', err);
        this.shutterAudio = null;
      }
    }

    /** Play shutter sound (non-blocking). */
    playShutter() {
      if (!this.shutterAudio) return;
      try {
        // Reset playback to start and play. Use play() promise to catch errors.
        // This avoids creating a new Audio each shot and reduces latency.
        this.shutterAudio.currentTime = 0;
        const p = this.shutterAudio.play();
        if (p && p.catch) {
          p.catch(err => {
            // Common reasons: user gesture policy, audio device not available
            // We ignore and let capture continue silently.
            // Optionally you could attempt new Audio(this.shutterUrl).play();
            console.debug('Shutter play rejected:', err);
          });
        }
      } catch (e) {
        console.warn('playShutter error:', e);
      }
    }

    /** Adjust playback speed (must be > 0). */
    setPlaybackSpeed(speed) {
      if (speed > 0) this.playbackSpeed = speed;
    }

    /** Handle error if video stream cannot be played. */
    videoCannotPlayHandler(e) {
      console.log('navigator.mediaDevices.getUserMedia error: ', e);
      this.messageDiv.innerText = "Cannot connect to camera.";
      return false;
    }

    /**
     * Set video and canvas dimensions.
     * Called after stream attachment or video metadata is loaded.
     */
    setDimensions(w, h) {
      this.w = w;
      this.h = h;

      this.video.width = w;
      this.video.height = h;

      this.snapshotCanvas.width = w;
      this.snapshotCanvas.height = h;

      this.playCanvas.width = w;
      this.playCanvas.height = h;
    }

    /** Toggle capture flip (180Â° rotation). */
    flip() {
      this._flip = !this._flip;
    }

    /**
     * Attempt to attach a video stream with progressively smaller resolutions
     * until successful. Returns the acquired stream or null if failed.
     */
    async attachStream() {
      this.messageDiv.innerText = "";

      // Try different camera resolutions, largest first
      const constraintsList = [
        { video: { width: 1920, height: 1080, facingMode: "environment" }, audio: false },
        { video: { width: 1600, height: 1200, facingMode: "environment" }, audio: false },
        { video: { width: 1280, height: 960,  facingMode: "environment" }, audio: false },
        { video: { width: 1280, height: 720,  facingMode: "environment" }, audio: false },
        { video: { width: 1024, height: 768,  facingMode: "environment" }, audio: false },
        { video: { width: 800,  height: 600,  facingMode: "environment" }, audio: false },
        { video: { width: 640,  height: 480,  facingMode: "environment" }, audio: false },
        { video: { width: 320,  height: 240,  facingMode: "environment" }, audio: false },
      ];

      let stream = null;
      for (const constraints of constraintsList) {
        try {
          stream = await navigator.mediaDevices.getUserMedia(constraints);
          console.log("Got stream with constraints:", constraints);
          break;
        } catch (err) {
          console.warn("Failed to get stream with constraints", constraints, err);
        }
      }

      if (!stream) {
        this.messageDiv.textContent = "Camera access denied or no camera found.";
        return null;
      }

      // Attach the stream to the video element
      this.video.srcObject = stream;
      this.videoStream = stream;
      this.streamOn = true;

      // Wait for metadata (resolution info)
      await new Promise((resolve) => {
        this.video.onloadedmetadata = () => resolve();
      });

      const actualWidth = this.video.videoWidth;
      const actualHeight = this.video.videoHeight;
      console.log(`Actual video dimensions: ${actualWidth}x${actualHeight}`);

      this.setDimensions(actualWidth, actualHeight);

      // Resize canvas and container styles to match video dimensions
      [this.snapshotCanvas, this.playCanvas].forEach((canvas) => {
        canvas.style.width = actualWidth + "px";
        canvas.style.height = actualHeight + "px";
      });

      const videoContainer = document.getElementById("video-container");
      videoContainer.style.width = actualWidth + "px";
      videoContainer.style.height = actualHeight + "px";

      const progressContainer = document.getElementById("progress-container");
      if (progressContainer) {
        progressContainer.style.width = actualWidth + "px";
      }

      const thumbnailContainer = document.getElementById("thumbnail-container");
      if (thumbnailContainer) {
        thumbnailContainer.style.maxWidth = actualWidth + "px";
      }

      this.messageDiv.textContent = "";
      return stream;
    }

    /** Detach and stop the current video stream. */
    detachStream() {
      if (!this.video.srcObject) return;
      this.video.pause();
      this.video.srcObject.getVideoTracks()[0].stop();
      this.streamOn = false;
      this.video.srcObject = null;
    }

    /** Returns true if playback timer is running. */
    isPlaying() {
      return !!this.playTimer;
    }

    /**
     * Toggle live video stream on/off.
     * Returns a promise resolving to true if playing, false if stopped.
     */
    toggleVideo() {
      if (this.video.paused) {
        if (this.video.srcObject && this.video.srcObject.active) {
          this.streamOn = true;
          return this.video.play()
            .then(() => true)
            .catch(() => false);
        } else {
          return this.attachStream(this.videoSourceId);
        }
      } else {
        this.video.pause();
        this.detachStream();
        this.streamOn = false;
        return new Promise((resolve) => resolve(false));
      }
    }

    /**
     * Draw a captured frame onto the given context.
     * @param {number} frameNumber - Index of frame in this.frames.
     */
    drawFrame(frameNumber, context) {
      context.clearRect(0, 0, this.w, this.h);
      context.drawImage(this.frames[frameNumber], 0, 0, this.w, this.h);
    }

    /**
     * Capture a frame from the video stream into a canvas.
     * Stores both the raw frame and a promise for its encoded WebP.
     */
    capture() {
      if (!this.streamOn) return;

      // play shutter sound
      this.playShutter();

      let imageCanvas = document.createElement('canvas');
      imageCanvas.width = this.w;
      imageCanvas.height = this.h;
      let context = imageCanvas.getContext('2d', { alpha: false });

      // Apply flip transform if enabled
      if (this._flip) {
        context.rotate(Math.PI);
        context.translate(-this.w, -this.h);
      }

      // Draw the current video frame
      context.drawImage(this.video, 0, 0, this.w, this.h);
      this.frames.push(imageCanvas);

      // Create promise to encode frame as WebP
      let promise = new Promise(((resolve) => {
        if (self.requestIdleCallback) {
          requestIdleCallback(() => {
            imageCanvas.toBlob(blob => resolve(blob), 'image/webp', 0.99999);
          });
        } else {
          imageCanvas.toBlob(blob => resolve(blob), 'image/webp', 0.99999);
        }

        // Onion skin: overlay last captured frame onto snapshot canvas
        this.snapshotContext.clearRect(0, 0, this.w, this.h);
        if (this.onionSkinEnabled) {
          this.snapshotContext.drawImage(imageCanvas, 0, 0, this.w, this.h);
        }
      }).bind(this));

      this.frameWebps.push(promise);
    }

    /**
     * Undo the last captured frame.
     * Updates onion skin preview if enabled.
     */
    undoCapture() {
      this.frames.pop();
      this.frameWebps.pop();
      this.snapshotContext.clearRect(0, 0, this.w, this.h);
      if (this.onionSkinEnabled && this.frames.length) {
        this.snapshotContext.drawImage(
          this.frames[this.frames.length - 1], 0, 0, this.w, this.h
        );
      }
    }

    /** Calculate frame display interval in milliseconds. */
    frameTimeout() {
      return 1000.0 / this.playbackSpeed;
    }

    /**
     * Begin playback of captured frames.
     * @param {boolean} noAudio - If true, disables audio playback.
     */
    startPlay(noAudio) {
      return new Promise((resolve) => {
        if (!this.frames.length) {
          resolve(false);
          return;
        }

        this.snapshotCanvas.style.visibility = 'hidden';
        this.video.pause();
        this.drawFrame(0, this.playContext);
        this.zeroPlayTime = performance.now();

        // Schedule first frame playback
        this.playTimer = setTimeout(
          this.playFrame.bind(this),
          this.frameTimeout(),
          1,
          resolve
        );

        // Play audio if present and enabled
        if (this.audio && !noAudio) {
          this.audio.currentTime = 0;
          this.audio.play();
        }
      });
    }

    /**
     * Stop playback, cleanup timers and audio,
     * and restore video feed if active.
     */
    endPlay(cb) {
      if (this.isPlaying()) clearTimeout(this.playTimer);
      this.playTimer = null;

      if (this.audioRecorder && this.audioRecorder.state === "recording") {
        this.audioRecorder.stop();
      } else if (this.audio) {
        this.audio.pause();
      }

      this.playContext.clearRect(0, 0, this.w, this.h);
      this.snapshotCanvas.style.visibility = '';

      if (this.streamOn) this.video.play();
      if (cb) cb();
    }

    /**
     * Display a frame and schedule the next frame playback.
     * @param {number} frameNumber - Frame index to display.
     */
    playFrame(frameNumber, cb) {
      if (frameNumber >= this.frames.length) {
        // Delay a moment before ending
        this.playTimer = setTimeout(this.endPlay.bind(this), 1000, cb);
      } else {
        this.drawFrame(frameNumber, this.playContext);
        let timeout = this.zeroPlayTime
          + ((frameNumber + 1) * this.frameTimeout())
          - performance.now();
        this.playTimer = setTimeout(
          this.playFrame.bind(this),
          timeout,
          frameNumber + 1,
          cb
        );
      }
    }

    /** Toggle between play and stop states. */
    togglePlay() {
      if (this.isPlaying()) {
        return new Promise((resolve) => {
          this.endPlay();
          resolve(true);
        });
      } else {
        return this.startPlay();
      }
    }

    /**
     * Clear all frames and audio, reset canvas and metadata.
     */
    clear() {
      if (this.isPlaying()) this.endPlay();
      if (this.audioBlob) this.audioBlob = null;
      this.setAudioSrc(null);

      if (this.frames.length === 0) return;

      this.frames = [];
      this.frameWebps = [];
      this.snapshotContext.clearRect(0, 0, this.w, this.h);
      this.playContext.clearRect(0, 0, this.w, this.h);
      this.name = null;
    }

    /**
     * Called after frames finish loading from a file.
     * Shows last frame as onion skin and begins playback.
     */
    loadFinished() {
      this.snapshotContext.clearRect(0, 0, this.w, this.h);
      if (this.onionSkinEnabled && this.frames.length) {
        this.snapshotContext.drawImage(
          this.frames[this.frames.length - 1], 0, 0, this.w, this.h
        );
      }
      this.startPlay();
    }

    /**
     * Add a decoded VP8 frame into the animation sequence.
     */
    addFrameVP8(frameOffset, blob, idx) {
      let blobURL = URL.createObjectURL(blob);
      let image = new Image(this.w, this.h);
      this.framesInFlight++;

      image.addEventListener("error", (evt => {
        if (evt.target.getAttribute('triedvp8l')) {
          console.log(evt);
          this.framesInFlight--;
          URL.revokeObjectURL(blobURL);
          image = null;
          if (this.framesInFlight === 0) this.loadFinished();
        } else {
          evt.target.setAttribute('triedvp8l', true);
          URL.revokeObjectURL(blobURL);
          blob = webm.vp8tovp8l(blob);
          blobURL = URL.createObjectURL(blob);
          evt.target.src = blobURL;
        }
      }).bind(this));

      image.addEventListener("load", (evt => {
        let newCanvas = document.createElement('canvas');
        newCanvas.width = this.w;
        newCanvas.height = this.h;
        newCanvas.getContext('2d', { alpha: false })
          .drawImage(evt.target, 0, 0, this.w, this.h);

        this.frames[frameOffset + idx] = newCanvas;
        this.frameWebps[frameOffset + idx] = new Promise((resolve) => {
          resolve(blob);
        });

        this.framesInFlight--;
        URL.revokeObjectURL(blobURL);
        if (this.framesInFlight === 0) this.loadFinished();
      }).bind(this));

      image.src = blobURL;
    }

    /**
     * Set the audio source from a blob.
     * Revokes any existing audio object URLs.
     */
    setAudioSrc(blob) {
      this.audioBlob = blob;
      if (this.audio) {
        URL.revokeObjectURL(this.audio.src);
        this.audio = null;
      }
      if (blob) {
        this.audio = document.createElement('audio');
        this.audio.src = URL.createObjectURL(blob);
      }
    }

    /**
     * Save the animation as a WebM file.
     * @param {string} filename - Desired filename (default: StopMotion.webm).
     */
    save(filename) {
      filename = filename || 'StopMotion';
      if (!filename.endsWith('.webm')) filename += '.webm';
      let title = filename.substr(0, filename.length - 5);

      return this.encode(title).then((blob => {
        this.exported = blob;
        let url = URL.createObjectURL(blob);

        let downloadLink = document.createElement('a');
        downloadLink.download = filename;
        downloadLink.href = url;
        downloadLink.click();

        URL.revokeObjectURL(url);
        return blob;
      }).bind(this));
    }

    /**
     * Encode frames (and optional audio) into a WebM file.
     */
    encode(title) {
      if (!this.audioBlob) {
        return webm.encode(
          title, this.w, this.h, this.frameTimeout(), this.frameWebps, null
        );
      }

      let fr = new FileReader();
      let an = this;

      return new Promise((resolve) => {
        fr.addEventListener("loadend", () => {
          webm.encode(
            title, an.w, an.h, an.frameTimeout(), an.frameWebps, fr.result
          ).then(resolve);
        });
        fr.readAsArrayBuffer(an.audioBlob);
      });
    }

    /**
     * Load an animation from a WebM file.
     * Decodes frames and audio into memory.
     */
    load(file, finishCB, frameRateCB) {
      let an = this;
      let frameOffset = this.frames.length;
      let reader = new FileReader();

      reader.addEventListener("loadend", evt => {
        webm.decode(
          evt.target.result,
          an.setDimensions.bind(an),
          frameRateCB,
          an.addFrameVP8.bind(an, frameOffset),
          an.setAudioSrc.bind(an)
        );
        an.name = file.name.substring(0, file.name.length - 5);
        if (finishCB) finishCB();
      });

      reader.readAsArrayBuffer(file);
    }

    /**
     * Record audio using MediaRecorder while playback occurs.
     */
    recordAudio(stream) {
      return new Promise(((resolve) => {
        if (!this.frames.length) {
          resolve(null);
          return;
        }

        let state = this.audioRecorder ? this.audioRecorder.state : "inactive";
        if (state === "recording") {
          resolve(null);
          return;
        }

        this.audioRecorder = new MediaRecorder(stream, {
          mimeType: "audio/webm;codecs=opus"
        });

        this.audioRecorder.ondataavailable = (evt => {
          this.audioChunks.push(evt.data);
        }).bind(this);

        this.audioRecorder.onstop = (() => {
          this.audioRecorder = null;
          this.setAudioSrc(new Blob(
            this.audioChunks, { 'type': 'audio/webm;codecs=opus' }
          ));
          this.audioChunks = [];
          resolve(this.audioBlob);
        }).bind(this);

        this.startPlay(true); // Play silently while recording
        this.audioRecorder.start();
      }).bind(this));
    }

    /** Clear audio recording if no active recorder. */
    clearAudio() {
      if (this.audioRecorder) return;
      this.setAudioSrc(null);
    }

    /**
     * Toggle onion skin mode on/off.
     * Updates snapshot canvas with last frame if enabled.
     */
    toggleOnionSkin() {
      this.onionSkinEnabled = !this.onionSkinEnabled;
      this.snapshotContext.clearRect(0, 0, this.w, this.h);

      if (this.onionSkinEnabled && this.frames.length) {
        this.snapshotContext.drawImage(
          this.frames[this.frames.length - 1], 0, 0, this.w, this.h
        );
      }
    }
  }

  // Expose Animator class
  animator.Animator = Animator;
})();
